import sys
import json
import os
import requests
import telegram
from datetime import datetime, timedelta
from pathlib import Path
from typing import (Optional, Dict, Any, List, Tuple, DefaultDict, BinaryIO, IO)
from collections import defaultdict

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°æ¨¡å—æœç´¢è·¯å¾„
_project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(_project_root))
from utils.log_utils import LogUtils


# --------------------------
# é…ç½®æ¨¡å—
# --------------------------
class Config:
    """å…¨å±€é…ç½®ç±»"""
    # æ—¶é—´æ ¼å¼
    MESSAGE_DATE_FORMAT = "%Y-%m-%d %H:%M:%S"
    INFO_DATE_FORMAT = "%Y-%m-%dT%H:%M:%S"

    # æ–‡ä»¶è·¯å¾„
    DEFAULT_DOWNLOAD_DIR = "../downloads"
    DEFAULT_OUTPUT_DIR = "../output"

    # Telegramé…ç½®
    TELEGRAM_LIMITS = {
        'images': 10 * 1024 * 1024,  # 10MB
        'videos': 50 * 1024 * 1024,  # 50MB
        'caption': 1024,  # æ¶ˆæ¯æˆªæ–­é•¿åº¦
        'media_group': 10,  # åª’ä½“åˆ†ç»„æœ€å¤šæ–‡ä»¶æ•°
    }

    # ä¸šåŠ¡å‚æ•°
    MAX_DOWNLOAD_ATTEMPTS = 10  # é‡è¯•æ¬¡æ•°
    ERROR_TRUNCATE = 50  # é”™è¯¯ä¿¡æ¯æˆªæ–­é•¿åº¦
    NOTIFICATION_TRUNCATE = 200  # é€šçŸ¥æ¶ˆæ¯æˆªæ–­é•¿åº¦

    @classmethod
    def get_env_vars(cls) -> Dict[str, str]:
        """ç¯å¢ƒå˜é‡è·å–"""
        return {
            'bot_token': os.getenv('BOT_TOKEN'),
            'chat_id': os.getenv('CHAT_ID'),
            'lark_key': os.getenv('LARK_KEY')
        }


# --------------------------
# å¼‚å¸¸ç±»
# --------------------------
class FileTooLargeError(Exception):
    """æ–‡ä»¶å¤§å°è¶…è¿‡å¹³å°é™åˆ¶å¼‚å¸¸"""
    pass


class MaxAttemptsError(Exception):
    """è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°å¼‚å¸¸"""
    pass


# å¼•å…¥æ—¥å¿—æ¨¡å—
logger = LogUtils().get_logger()
logger.info("ğŸ”„ T-Bot åˆå§‹åŒ–å®Œæˆ")


# --------------------------
# é€šçŸ¥æ¨¡å—
# --------------------------
class Notifier:
    """é€šçŸ¥å¤„ç†å™¨"""

    @staticmethod
    def send_lark_message(message: str) -> bool:
        """å‘é€æ™®é€šé£ä¹¦æ¶ˆæ¯"""
        lark_key = Config.get_env_vars()['lark_key']
        if not lark_key:
            return False

        webhook_url = f"https://open.feishu.cn/open-apis/bot/v2/hook/{lark_key}"
        try:
            payload = {
                "msg_type": "text",
                "content": {"text": f"ğŸ“¢ åŠ¨æ€æ›´æ–°\n{message}"}
            }
            response = requests.post(webhook_url, json=payload, timeout=10)
            response.raise_for_status()
            logger.info("ğŸ“¨ é£ä¹¦åŠ¨æ€æ¶ˆæ¯å‘é€æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âœ— é£ä¹¦æ¶ˆæ¯å‘é€å¤±è´¥: {str(e)}")
            return False

    @staticmethod
    def send_lark_alert(message: str) -> bool:
        """å‘é€é£ä¹¦é€šçŸ¥"""
        if not Config.get_env_vars()['lark_key']:
            return False

        # æ¶ˆæ¯æˆªæ–­
        truncated_msg = f"{message[:Config.NOTIFICATION_TRUNCATE]}..." if len(
            message) > Config.NOTIFICATION_TRUNCATE else message
        webhook_url = f"https://open.feishu.cn/open-apis/bot/v2/hook/{Config.get_env_vars()['lark_key']}"

        try:
            payload = {
                "msg_type": "text",
                "content": {"text": f"ğŸ“¢ XT-Botå¤„ç†å‘Šè­¦\n{truncated_msg}"}
            }
            response = requests.post(webhook_url, json=payload, timeout=10)
            response.raise_for_status()
            logger.info("ğŸ“¨ é£ä¹¦é€šçŸ¥å‘é€æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âœ— é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥: {str(e)}")
            return False


# --------------------------
# æ–‡ä»¶å¤„ç†æ¨¡å—
# --------------------------
class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""

    def __init__(self, json_path: str, download_dir: str):
        self.json_path = Path(json_path)
        self.download_path = Path(download_dir)
        self._ensure_dirs()

    def _ensure_dirs(self) -> None:
        """ç›®å½•åˆ›å»º"""
        self.download_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“‚ ä¸‹è½½ç›®å½•å·²å°±ç»ª: {self.download_path}")

    def load_data(self) -> List[Dict[str, Any]]:
        """åŠ è½½JSONæ•°æ®"""
        try:
            with self.json_path.open('r+', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"ğŸ“„ å·²åŠ è½½JSONæ•°æ®ï¼Œå…±{len(data)}æ¡è®°å½•")
                return data
        except Exception as e:
            logger.error(f"âœ— JSONæ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def save_data(self, data: List[Dict[str, Any]]) -> None:
        """ä¿å­˜JSONæ•°æ®"""
        try:
            with self.json_path.open('r+', encoding='utf-8') as f:
                f.seek(0)
                json.dump(data, f, indent=2, ensure_ascii=False)
                f.truncate()
        except Exception as e:
            logger.error(f"âœ— JSONä¿å­˜å¤±è´¥: {str(e)}")
            raise


# --------------------------
# ä¸‹è½½æ¨¡å—
# --------------------------
class DownloadManager:
    """ä¸‹è½½ç®¡ç†å™¨"""

    @classmethod
    def process_item(cls, item: Dict[str, Any], processor: FileProcessor) -> None:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ä¸‹è½½"""
        # å¤„ç†ç‰¹æ®Šç±»å‹ï¼ˆspaces/broadcastsï¼‰ç›´æ¥è¿”å›
        if cls._is_special_type(item):
            cls._handle_special_type(item)
            return

        # å¦‚æœå·²ä¸‹è½½æˆ–è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œç›´æ¥è¿”å›
        if cls._should_skip_download(item):
            return

        # æ‰§è¡Œä¸‹è½½æ“ä½œ
        try:
            logger.info(f"â¬ å¼€å§‹ä¸‹è½½: {item['file_name']}")
            file_path = cls._download_file(item, processor)

            # å¤„ç†ä¸‹è½½æˆåŠŸ
            size_mb = cls._handle_download_success(item, file_path)
            logger.info(f"âœ“ ä¸‹è½½æˆåŠŸ: {item['file_name']} ({size_mb}MB)")

        except Exception as e:
            # å¤„ç†ä¸‹è½½å¤±è´¥
            cls._handle_download_failure(item, e)

    @classmethod
    def _is_special_type(cls, item: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šç±»å‹ï¼ˆspaces/broadcastsï¼‰"""
        return item.get('media_type') in ['spaces', 'broadcasts']

    @classmethod
    def _handle_special_type(cls, item: Dict[str, Any]) -> None:
        """å¤„ç†ç‰¹æ®Šç±»å‹é¡¹"""
        if item.get('is_downloaded'):
            return

        item.update({
            "is_downloaded": True,
            "download_info": {
                "success": True,
                "size_mb": 0,
                "timestamp": datetime.now().strftime(Config.INFO_DATE_FORMAT),
                "download_attempts": 0
            }
        })
        logger.info(f"â­ è·³è¿‡ç‰¹æ®Šç±»å‹ä¸‹è½½: {item['file_name']}")

    @classmethod
    def _should_skip_download(cls, item: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡ä¸‹è½½"""
        # å·²ä¸‹è½½çš„ç›´æ¥è·³è¿‡
        if item.get('is_downloaded'):
            return True

        download_info = item.setdefault('download_info', {})
        current_attempts = download_info.get('download_attempts', 0)

        # è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°
        if current_attempts >= Config.MAX_DOWNLOAD_ATTEMPTS:
            # è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°
            cls._handle_max_attempts(item)
            return True

        return False

    @classmethod
    def _download_file(cls, item: Dict[str, Any], processor: FileProcessor) -> Path:
        """æ‰§è¡Œæ–‡ä»¶ä¸‹è½½æ“ä½œ"""
        response = requests.get(item['url'], stream=True, timeout=30)
        response.raise_for_status()

        file_path = processor.download_path / item['file_name']
        with open(file_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        return file_path

    @classmethod
    def _handle_download_success(cls, item: Dict[str, Any], file_path: Path) -> float:
        """å¤„ç†ä¸‹è½½æˆåŠŸçš„æƒ…å†µï¼Œè¿”å›æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
        file_size = os.path.getsize(file_path)
        size_mb = round(file_size / 1024 / 1024, 2)

        item.update({
            "is_downloaded": True,
            "download_info": {
                "success": True,
                "size_mb": size_mb,
                "timestamp": datetime.now().strftime(Config.INFO_DATE_FORMAT),
                "download_attempts": 0  # é‡ç½®è®¡æ•°å™¨
            }
        })
        return size_mb

    @classmethod
    def _handle_download_failure(cls, item: Dict[str, Any], error: Exception) -> None:
        """å¤„ç†ä¸‹è½½å¤±è´¥çš„æƒ…å†µ"""
        download_info = item.setdefault('download_info', {})
        current_attempts = download_info.get('download_attempts', 0)
        new_attempts = current_attempts + 1

        # æ›´æ–°ä¸‹è½½ä¿¡æ¯
        download_info.update({
            "success": False,
            "error_type": "download_error",
            "message": str(error),
            "timestamp": datetime.now().strftime(Config.INFO_DATE_FORMAT),
            "download_attempts": new_attempts
        })

        # é”™è¯¯æ—¥å¿—
        truncated_error = str(error)[:Config.ERROR_TRUNCATE]
        error_msg = f"âœ— ä¸‹è½½å¤±è´¥: {item['file_name']} - {truncated_error} (å°è¯• {new_attempts}/{Config.MAX_DOWNLOAD_ATTEMPTS})"
        logger.error(error_msg)

        # è°ƒè¯•æ—¥å¿—
        logger.debug(f"âœ— ä¸‹è½½å¤±è´¥è¯¦æƒ…: {item['file_name']} - {str(error)}")

    @classmethod
    def _handle_max_attempts(cls, item: Dict[str, Any]) -> None:
        """å¤„ç†è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°çš„æƒ…å†µ"""
        # å‡†å¤‡è¦è®¾ç½®çš„é»˜è®¤å€¼
        new_info = {
            "success": False,
            "error_type": "max_download_attempts",
            "message": "è¿ç»­ä¸‹è½½å¤±è´¥10æ¬¡",
            "notification_sent": False
        }

        # å¦‚æœå·²æœ‰upload_infoï¼Œå¤ç”¨å…¶ä¸­çš„æŸäº›å­—æ®µ
        if 'upload_info' in item and isinstance(item['upload_info'], dict):
            existing_info = item['upload_info']

            # ä¿ç•™å·²æœ‰çš„æ—¶é—´æˆ³ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'timestamp' in existing_info:
                new_info['timestamp'] = existing_info['timestamp']
            else:
                new_info['timestamp'] = datetime.now().strftime(Config.INFO_DATE_FORMAT)

            # ä¿ç•™å·²æœ‰çš„é€šçŸ¥çŠ¶æ€ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'notification_sent' in existing_info:
                new_info['notification_sent'] = existing_info['notification_sent']
        else:
            # æ²¡æœ‰å·²æœ‰ä¿¡æ¯ï¼Œåˆ›å»ºæ–°çš„æ—¶é—´æˆ³
            new_info['timestamp'] = datetime.now().strftime(Config.INFO_DATE_FORMAT)

        # æ›´æ–°æˆ–åˆ›å»ºupload_info
        item['upload_info'] = new_info

        logger.warning(f"â­ å·²è¾¾æœ€å¤§ä¸‹è½½å°è¯•æ¬¡æ•°: {item['file_name']}")


# --------------------------
# ä¸Šä¼ æ¨¡å—
# --------------------------
class UploadManager:
    """ä¸Šä¼ ç®¡ç†å™¨"""

    def __init__(self):
        self._initialize_bot()
        self.strategies = {
            'text': self._handle_text_upload,
            'single': self._handle_single_media,
            'group': self._handle_media_group
        }
        self.processor = None  # æ–‡ä»¶å¤„ç†å™¨å¼•ç”¨

    def _initialize_bot(self):
        """åˆå§‹åŒ–Telegramæœºå™¨äºº"""
        env_vars = Config.get_env_vars()
        if not env_vars['bot_token'] or not env_vars['chat_id']:
            logger.error("âŒ å¿…é¡»é…ç½® BOT_TOKEN å’Œ CHAT_ID ç¯å¢ƒå˜é‡ï¼")
            sys.exit(1)
        self.bot = telegram.Bot(token=env_vars['bot_token'])
        self.chat_id = env_vars['chat_id']

    def process_items(self, items: List[Dict[str, Any]], processor: FileProcessor) -> None:
        """
        å¤„ç†å¾…ä¸Šä¼ é¡¹çš„ä¸»å…¥å£
        """
        # ä¿å­˜å¤„ç†å™¨å¼•ç”¨ï¼Œä¾›åç»­ä½¿ç”¨
        self.processor = processor

        # è¿‡æ»¤å‡ºå¯ä¸Šä¼ çš„é¡¹
        upload_queue = self._filter_uploadable_items(items)
        if not upload_queue:
            return

        # ç­–ç•¥åˆ†å‘ä¸­å¿ƒ
        strategy_map = self._create_strategy_map(upload_queue)

        # æŒ‰ç­–ç•¥ç±»å‹å¤„ç†
        for strategy_type, items_to_upload in strategy_map.items():
            try:
                if strategy_type == 'group':
                    # æŒ‰æ¨æ–‡åˆ†ç»„å¤„ç†åª’ä½“ç»„
                    grouped_items = self._group_by_tweet_id(items_to_upload)
                    for tweet_items in grouped_items:
                        self.strategies[strategy_type](tweet_items, processor)
                else:
                    self.strategies[strategy_type](items_to_upload, processor)
            except Exception as e:
                self._handle_strategy_error(e, items_to_upload, strategy_type)

    def _filter_uploadable_items(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¿‡æ»¤å‡ºå¯ä¸Šä¼ çš„é¡¹"""
        return [
            item for item in items
            if not item.get('is_uploaded') and self._is_eligible_for_upload(item)
        ]

    def _is_eligible_for_upload(self, item: Dict[str, Any]) -> bool:
        """åˆ¤æ–­é¡¹æ˜¯å¦é€‚åˆä¸Šä¼ """
        # æ£€æŸ¥ä¸å¯æ¢å¤çš„é”™è¯¯
        if self._has_unrecoverable_error(item):
            return False
        # ç‰¹æ®Šç±»å‹ï¼ˆæ–‡æœ¬ï¼‰å¯ç›´æ¥ä¸Šä¼ 
        if item.get('media_type') in ['spaces', 'broadcasts']:
            return True
        # å¸¸è§„ç±»å‹éœ€è¦ä¸‹è½½æˆåŠŸ
        return item.get('is_downloaded', False)

    def _create_strategy_map(self, items: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        åˆ›å»ºä¸Šä¼ ç­–ç•¥æ˜ å°„ï¼š
        - 'text': æ–‡æœ¬ç±»å‹é¡¹
        - 'single': å•åª’ä½“é¡¹
        - 'group': åª’ä½“ç»„é¡¹
        """
        strategy_map = defaultdict(list)

        for item in items:
            media_type = item['media_type']

            if media_type in ['spaces', 'broadcasts']:
                strategy_map['text'].append(item)

            elif media_type in ['images', 'videos']:
                # å¯¹åª’ä½“æ–‡ä»¶è¿›è¡Œåˆ†ç»„ï¼ˆåª’ä½“æ•°é‡å†³å®šç­–ç•¥ï¼‰
                media_count = self._get_media_count_in_tweet(items, item['tweet_id'])

                if media_count == 1:
                    strategy_map['single'].append(item)
                else:
                    strategy_map['group'].append(item)

        return dict(strategy_map)

    def _get_media_count_in_tweet(self, all_items: List[Dict[str, Any]], tweet_id: str) -> int:
        """è·å–åŒä¸€æ¨æ–‡ä¸­çš„åª’ä½“é¡¹æ•°é‡"""
        return sum(
            1 for item in all_items
            if item['tweet_id'] == tweet_id
            and item['media_type'] in ['images', 'videos']
            and not item.get('is_uploaded')
        )

    def _group_by_tweet_id(self, items: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """æŒ‰æ¨æ–‡IDåˆ†ç»„é¡¹"""
        grouped = defaultdict(list)
        for item in items:
            grouped[item['tweet_id']].append(item)
        return list(grouped.values())

    # --------------------------
    # ä¸Šä¼ ç­–ç•¥å®ç°
    # --------------------------
    def _handle_text_upload(self, items: List[Dict[str, Any]], processor: FileProcessor) -> None:
        """å¤„ç†æ–‡æœ¬é¡¹ä¸Šä¼ ç­–ç•¥"""
        for item in items:
            self._upload_text_item(item)

    def _handle_single_media(self, items: List[Dict[str, Any]], processor: FileProcessor) -> None:
        """å¤„ç†å•åª’ä½“é¡¹ä¸Šä¼ ç­–ç•¥"""
        for item in items:
            try:
                self._upload_media_item(item, processor)
            except Exception as e:
                self._handle_single_upload_error(e, item)

    def _handle_media_group(self, items: List[Dict[str, Any]], processor: FileProcessor) -> None:
        """å¤„ç†åª’ä½“ç»„ä¸Šä¼ ç­–ç•¥"""
        tweet_id = items[0]['tweet_id']
        logger.info(f"ğŸ–¼ï¸ å‡†å¤‡åª’ä½“ç»„ä¸Šä¼ : {tweet_id} ({len(items)}ä¸ªæ–‡ä»¶)")

        # æå‰æ£€æŸ¥åª’ä½“ç»„å¤§å°
        if self._is_group_size_exceeded(items):
            logger.warning(f"âš ï¸ åª’ä½“ç»„è¿‡å¤§({self._get_group_size_mb(items)}MB > 50MB)ï¼Œå›é€€ä¸ºå•æ–‡ä»¶ä¸Šä¼ ")
            self._fallback_to_single_upload(items)
            return

        # æ„å»ºåª’ä½“ç»„
        media_group, included_items = self._prepare_media_group(items, processor)

        if not media_group:
            logger.warning(f"â­ æ— å¯ä¸Šä¼ çš„æœ‰æ•ˆåª’ä½“: {tweet_id}")
            return

        try:
            # å‘é€åª’ä½“ç»„
            messages = self.bot.send_media_group(
                chat_id=self.chat_id,
                media=media_group
            )

            # éªŒè¯å“åº”
            if len(messages) != len(included_items):
                logger.warning(
                    f"âš ï¸ è¿”å›æ¶ˆæ¯æ•°é‡({len(messages)})ä¸åª’ä½“ç»„æ•°é‡({len(included_items)})ä¸åŒ¹é…ï¼Œå°†å›é€€ä¸ºå•æ–‡ä»¶ä¸Šä¼ "
                )
                # ä½¿ç”¨å›é€€æœºåˆ¶å¤„ç†ä¸åŒ¹é…æƒ…å†µ
                self._fallback_to_single_upload(included_items)
                return

            # æ›´æ–°çŠ¶æ€
            for msg, item in zip(messages, included_items):
                msg_id = msg.message_id
                self._update_upload_status(item, msg_id)
                logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {item['file_name']}({msg_id})")

            logger.info(f"âœ… åª’ä½“ç»„ä¸Šä¼ æˆåŠŸ: {tweet_id} ({len(media_group)}ä¸ªæ–‡ä»¶)")

        except Exception as e:
            self._handle_group_upload_error(e, included_items)

        finally:
            # ç¡®ä¿å…³é—­æ‰€æœ‰æ–‡ä»¶å¥æŸ„
            for media_item in media_group:
                if hasattr(media_item, 'media') and hasattr(media_item.media, 'close'):
                    media_item.media.close()

    # --------------------------
    # åª’ä½“ç»„å¤§å°æ£€æµ‹å’Œå›é€€
    # --------------------------
    def _handle_strategy_error(self, error: Exception, items: List[Dict[str, Any]], strategy_type: str) -> None:
        """å¤„ç†ç­–ç•¥çº§é”™è¯¯ï¼Œä¼˜åŒ–åª’ä½“ç»„å¤„ç†é€»è¾‘"""
        logger.error(f"âœ— {strategy_type}ç­–ç•¥æ‰§è¡Œå¤±è´¥: {str(error)[:Config.ERROR_TRUNCATE]}")
        logger.debug(f"âœ— {strategy_type}ç­–ç•¥æ‰§è¡Œå¤±è´¥è¯¦æƒ…: {str(error)}")

        # å¯¹äºåª’ä½“ç»„é”™è¯¯ï¼Œæ£€æŸ¥å¤§å°å†³å®šæ˜¯å¦å›é€€
        if strategy_type == 'group' and self._is_group_size_exceeded(items):
            logger.warning(f"âš ï¸ åª’ä½“ç»„è¿‡å¤§({self._get_group_size_mb(items)}MB > 50MB)ï¼Œå›é€€ä¸ºå•æ–‡ä»¶ä¸Šä¼ ")
            self._fallback_to_single_upload(items)
        elif strategy_type in ['group', 'text']:
            # å…¶ä»–ç±»å‹çš„åª’ä½“ç»„é”™è¯¯ä¹Ÿå°è¯•å›é€€
            self._fallback_to_single_upload(items)

    def _is_group_size_exceeded(self, items: List[Dict[str, Any]]) -> bool:
        """æ£€æŸ¥åª’ä½“ç»„æ€»å¤§å°æ˜¯å¦è¶…è¿‡50MBé™åˆ¶"""
        return self._get_group_size_mb(items) > Config.TELEGRAM_LIMITS['videos'] / (1024 * 1024)

    def _get_group_size_mb(self, items: List[Dict[str, Any]]) -> float:
        """è®¡ç®—åª’ä½“ç»„æ€»å¤§å°ï¼ˆMBï¼‰"""
        total_size_bytes = 0

        for item in items:
            if 'download_info' in item and 'size_mb' in item['download_info']:
                # ä½¿ç”¨å·²æœ‰å¤§å°ä¿¡æ¯
                total_size_bytes += item['download_info']['size_mb'] * 1024 * 1024
            else:
                # å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè·å–å¤§å°
                try:
                    file_path = self.processor.download_path / item['file_name']
                    if file_path.exists():
                        total_size_bytes += os.path.getsize(file_path)
                except Exception:
                    continue

        return round(total_size_bytes / (1024 * 1024), 2)

    def _fallback_to_single_upload(self, items: List[Dict[str, Any]]) -> None:
        """å›é€€ä¸ºå•æ–‡ä»¶ä¸Šä¼ ç­–ç•¥"""
        logger.info(f"â®ï¸ å›é€€ä¸ºå•æ–‡ä»¶ä¸Šä¼ : {items[0]['tweet_id']} ({len(items)}ä¸ªæ–‡ä»¶)")

        for item in items:
            if item.get('is_uploaded'):
                continue

            try:
                if item['media_type'] in ['spaces', 'broadcasts']:
                    self._upload_text_item(item)
                else:
                    self._upload_media_item(item, self.processor)
            except Exception as inner_error:
                self._update_error_status(inner_error, item)
                self._reset_download_status(item)
                logger.error(f"âœ— å•æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {item['file_name']} - {str(inner_error)[:Config.ERROR_TRUNCATE]}")
                logger.debug(f"âœ— å•æ–‡ä»¶ä¸Šä¼ å¤±è´¥è¯¦æƒ…: {item['file_name']} - {str(inner_error)}")

    # --------------------------
    # å®é™…ä¸Šä¼ æ“ä½œ
    # --------------------------
    def _upload_text_item(self, item: Dict[str, Any]) -> None:
        """ä¸Šä¼ æ–‡æœ¬æ¶ˆæ¯"""
        # æ–‡æœ¬å‹captionæ„å»º
        caption = self._build_text_caption(item)
        msg = self.bot.send_message(chat_id=self.chat_id, text=caption)
        msg_id = msg.message_id
        self._update_upload_status(item, msg_id)

        # å‘é€é£ä¹¦é€šçŸ¥
        if Config.get_env_vars()['lark_key']:
            Notifier.send_lark_message(caption)

        logger.info(f"âœ… å‘é€æˆåŠŸ: {item['file_name']}({msg_id})")

    def _upload_media_item(self, item: Dict[str, Any], processor: FileProcessor) -> None:
        """ä¸Šä¼ å•ä¸ªåª’ä½“æ–‡ä»¶"""
        with self._get_file_handle(item, processor) as file_obj:
            # åª’ä½“å‹captionæ„å»º
            caption = self._build_media_caption(item)

            if item['media_type'] == 'images':
                msg = self.bot.send_photo(chat_id=self.chat_id, photo=file_obj, caption=caption)
            else:  # videos
                msg = self.bot.send_video(chat_id=self.chat_id, video=file_obj, caption=caption)

            msg_id = msg.message_id
            self._update_upload_status(item, msg_id)
            logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {item['file_name']}({msg_id})")

    def _prepare_media_group(self, items: List[Dict[str, Any]], processor: FileProcessor
                             ) -> Tuple[List[telegram.InputMedia], List[Dict[str, Any]]]:
        """
        å‡†å¤‡åª’ä½“ç»„ä¸Šä¼ 
        è¿”å›ï¼šåª’ä½“ç»„å¯¹è±¡åˆ—è¡¨, åŒ…å«çš„åŸå§‹é¡¹åˆ—è¡¨
        """
        media_group = []
        included_items = []
        tweet_id = items[0]['tweet_id']

        for idx, item in enumerate(items):
            if item.get('is_uploaded'):
                continue

            try:
                with self._get_file_handle(item, processor) as file_obj:
                    # ä»…ç¬¬ä¸€é¡¹æ·»åŠ caption
                    caption = self._build_media_caption(item) if idx == 0 else None

                    if item['media_type'] == 'images':
                        media_item = telegram.InputMediaPhoto(file_obj, caption=caption)
                    else:  # videos
                        media_item = telegram.InputMediaVideo(file_obj, caption=caption)

                    media_group.append(media_item)
                    included_items.append(item)

                    # æ£€æŸ¥åª’ä½“ç»„æ–‡ä»¶æ•°é™åˆ¶
                    if len(media_group) >= Config.TELEGRAM_LIMITS['media_group']:
                        logger.warning(f"âš ï¸ åª’ä½“ç»„æ–‡ä»¶æ•°è¾¾åˆ°ä¸Šé™: {tweet_id}")
                        break

            except Exception as e:
                self._handle_preparation_error(e, item)

        return media_group, included_items

    # --------------------------
    # captionæ„å»ºç³»ç»Ÿ
    # --------------------------
    def _build_text_caption(self, item: Dict[str, Any]) -> str:
        """
        æ–‡æœ¬å‹captionæ„å»º
        æ ¼å¼: #[ç”¨æˆ·å] #[ç±»å‹]
              [å‘å¸ƒæ—¶é—´]
              [åŸé“¾æ¥]
        """
        username = item['user']['screen_name']
        media_type = item['media_type']
        publish_time = datetime.fromisoformat(item['publish_time']).strftime(Config.MESSAGE_DATE_FORMAT)
        url = item['url']

        # ç»„åˆæ–‡æœ¬å…ƒç´ 
        content = f"#{username} #{media_type}\n{publish_time}\n{url}"
        return self._truncate_text(content, Config.TELEGRAM_LIMITS['caption'])

    def _build_media_caption(self, item: Dict[str, Any]) -> str:
        """
        åª’ä½“å‹captionæ„å»º
        æ ¼å¼: #[ç”¨æˆ·å] [æ˜¾ç¤ºå]
              [å‘å¸ƒæ—¶é—´]
              [æ¨æ–‡æ–‡æœ¬å†…å®¹]
        """
        screen_name = item['user']['screen_name']
        display_name = item['user']['name']
        publish_time = datetime.fromisoformat(item['publish_time']).strftime(Config.MESSAGE_DATE_FORMAT)

        # ç»„åˆåŸºæœ¬ä¿¡æ¯
        base_info = f"#{screen_name} {display_name}\n{publish_time}"

        # æ·»åŠ æ¨æ–‡å†…å®¹
        text_content = f"{base_info}\n{item.get('full_text', '')}"
        return self._truncate_text(text_content, Config.TELEGRAM_LIMITS['caption'])

    def _truncate_text(self, text: str, max_length: int) -> str:
        """æ™ºèƒ½æˆªæ–­æ–‡æœ¬"""
        if len(text) > max_length:
            truncated = text[:max_length - 3]
            # ç¡®ä¿æˆªæ–­åœ¨å®Œæ•´å¥å­å
            if truncated.rfind('.') > max_length - 10:
                truncate_point = truncated.rfind('.') + 1
            else:
                truncate_point = max_length - 3
            return text[:truncate_point] + "..."
        return text

    # --------------------------
    # è¾…åŠ©æ–¹æ³•
    # --------------------------
    def _get_file_handle(self, item: Dict[str, Any], processor: FileProcessor) -> BinaryIO:
        """è·å–æ–‡ä»¶å¥æŸ„å¹¶è¿›è¡Œå¤§å°éªŒè¯"""
        if item.get('media_type') in ['spaces', 'broadcasts']:
            # ç‰¹æ®Šç±»å‹ç›´æ¥è¿”å›URL
            return item['url']

        # å¤„ç†æœ¬åœ°æ–‡ä»¶
        file_path = processor.download_path / item['file_name']
        media_type = item['media_type']

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size > Config.TELEGRAM_LIMITS[media_type]:
            raise FileTooLargeError(
                f"{media_type}å¤§å°è¶…æ ‡ ({file_size / (1024 * 1024):.2f}MB > "
                f"{Config.TELEGRAM_LIMITS[media_type] / (1024 * 1024):.2f}MB)"
            )

        return open(file_path, 'rb')

    def _update_upload_status(self, item: Dict[str, Any], message_id: int) -> None:
        """æ›´æ–°ä¸Šä¼ çŠ¶æ€ä¸ºæˆåŠŸ"""
        item.update({
            "is_uploaded": True,
            "upload_info": {
                "success": True,
                "message_id": message_id,
                "timestamp": datetime.now().strftime(Config.INFO_DATE_FORMAT)
            }
        })

    # --------------------------
    # é”™è¯¯å¤„ç†ç³»ç»Ÿ
    # --------------------------
    def _has_unrecoverable_error(self, item: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ä¸å¯æ¢å¤é”™è¯¯"""
        upload_info = item.get('upload_info', {})
        error_type = upload_info.get('error_type')

        if error_type in ['file_too_large', 'max_download_attempts']:
            # å‘é€é€šçŸ¥ï¼ˆå¦‚æœå°šæœªå‘é€ï¼‰
            if not upload_info.get('notification_sent'):
                self._send_unrecoverable_alert(item, error_type)
                upload_info['notification_sent'] = True
            return True
        return False

    def _send_unrecoverable_alert(self, item: Dict[str, Any], error_type: str) -> None:
        """å‘é€ä¸å¯æ¢å¤é”™è¯¯é€šçŸ¥"""
        Notifier.send_lark_alert(
            f"ğŸ”´ æ¨é€å¤±è´¥\næ–‡ä»¶å: {item['file_name']}\n"
            f"ç±»å‹: {error_type}\n"
            f"é”™è¯¯: {item['upload_info']['message'][:Config.ERROR_TRUNCATE]}"
        )

    def _handle_single_upload_error(self, error: Exception, item: Dict[str, Any]) -> None:
        """å¤„ç†å•æ–‡ä»¶ä¸Šä¼ é”™è¯¯"""
        self._update_error_status(error, item)
        self._reset_download_status(item)
        logger.error(f"âœ— å•æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {item['file_name']} - {str(error)[:Config.ERROR_TRUNCATE]}")
        logger.debug(f"âœ— å•æ–‡ä»¶ä¸Šä¼ å¤±è´¥è¯¦æƒ…: {item['file_name']} - {str(error)}")

    def _handle_group_upload_error(self, error: Exception, items: List[Dict[str, Any]]) -> None:
        """å¤„ç†åª’ä½“ç»„ä¸Šä¼ é”™è¯¯"""
        for item in items:
            self._update_error_status(error, item)
            self._reset_download_status(item)
        tweet_id = items[0]['tweet_id'] if items else "æœªçŸ¥"
        logger.error(f"âœ— åª’ä½“ç»„ä¸Šä¼ å¤±è´¥: {tweet_id} - {str(error)[:Config.ERROR_TRUNCATE]}")
        logger.debug(f"âœ— åª’ä½“ç»„ä¸Šä¼ å¤±è´¥è¯¦æƒ…: {tweet_id} - {str(error)}")

    def _handle_preparation_error(self, error: Exception, item: Dict[str, Any]) -> None:
        """å¤„ç†åª’ä½“ç»„å‡†å¤‡è¿‡ç¨‹ä¸­çš„é”™è¯¯"""
        self._update_error_status(error, item)
        self._reset_download_status(item)
        logger.warning(f"âœ— åª’ä½“ç»„å‡†å¤‡å¤±è´¥: {item['file_name']}")

    def _update_error_status(self, error: Exception, item: Dict[str, Any]) -> None:
        """æ›´æ–°é”™è¯¯çŠ¶æ€"""
        error_type = 'file_too_large' if isinstance(error, FileTooLargeError) else 'api_error'

        item['upload_info'] = {
            "success": False,
            "error_type": error_type,
            "message": str(error),
            "timestamp": datetime.now().strftime(Config.INFO_DATE_FORMAT),
            "notification_sent": False
        }

        # å¯¹äºéæ–‡ä»¶å¤§å°é”™è¯¯ï¼Œç«‹å³é€šçŸ¥
        if error_type != 'file_too_large':
            Notifier.send_lark_alert(
                f"ğŸ”´ ä¸Šä¼ å¤±è´¥\næ–‡ä»¶å: {item['file_name']}\n"
                f"é”™è¯¯ç±»å‹: {error.__class__.__name__}\n"
                f"é”™è¯¯è¯¦æƒ…: {str(error)[:Config.ERROR_TRUNCATE]}"
            )

    def _reset_download_status(self, item: Dict[str, Any]) -> None:
        """é‡ç½®ä¸‹è½½çŠ¶æ€ä»¥å…è®¸é‡è¯•"""
        if 'is_downloaded' in item:
            item['is_downloaded'] = False


# --------------------------
# ä¸»æµç¨‹
# --------------------------
def process_single(json_path: str, download_dir: str = Config.DEFAULT_DOWNLOAD_DIR) -> None:
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    try:
        logger.info(f"\n{'-' * 40}\nğŸ” å¼€å§‹å¤„ç†: {json_path}")
        processor = FileProcessor(json_path, download_dir)
        data = processor.load_data()

        # 1. æŒ‰tweet_idåˆ†ç»„æ•°æ®
        grouped_items = defaultdict(list)
        for item in data:
            if 'tweet_id' not in item:
                logger.error(f"âš ï¸ æ•°æ®é¡¹ç¼ºå°‘tweet_id: æ–‡ä»¶å={item.get('file_name', 'æœªçŸ¥')}, è·³è¿‡")
                continue

            grouped_items[item['tweet_id']].append(item)

        download_manager = DownloadManager()
        upload_manager = UploadManager()

        logger.info(f"ğŸ“Š æ£€æµ‹åˆ° {len(grouped_items)} ä¸ªæ¨æ–‡åˆ†ç»„")

        # 2. æŒ‰åˆ†ç»„å¤„ç†
        for tweet_id, items in grouped_items.items():
            # 2.1 ä¸‹è½½ç»„å†…æ‰€æœ‰æœªä¸‹è½½çš„æ–‡ä»¶
            for item in items:
                if not item.get('is_downloaded'):
                    download_manager.process_item(item, processor)

            # 2.2 åˆ†ç»„ä¸Šä¼ ç­–ç•¥
            upload_manager.process_items(items, processor)

        processor.save_data(data)
        logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ\n{'-' * 40}\n")

    except Exception as e:
        logger.error(f"ğŸ’¥ å¤„ç†å¼‚å¸¸: {str(e)}", exc_info=True)
        Notifier.send_lark_alert(f"å¤„ç†å¼‚å¸¸: {str(e)[:Config.NOTIFICATION_TRUNCATE]}")
        raise


def batch_process(days: int = 7) -> None:
    """æ‰¹é‡å¤„ç†"""
    base_dir = Path(Config.DEFAULT_OUTPUT_DIR)
    for i in range(days, -1, -1):  # å€’åºå¤„ç†
        target_date = datetime.now() - timedelta(days=i)
        date_str = target_date.strftime("%Y-%m-%d")
        json_path = base_dir / f"{date_str[:7]}/{date_str}.json"

        if json_path.exists():
            process_single(str(json_path))
        else:
            logger.info(f"â­ è·³è¿‡ä¸å­˜åœ¨æ–‡ä»¶: {json_path}")


def main():
    args = sys.argv[1:]  # è·å–å‘½ä»¤è¡Œå‚æ•°

    if len(args) == 2:
        process_single(args[0], args[1])
    elif len(args) == 1:
        process_single(args[0])
    elif len(args) == 0:
        batch_process()
    else:
        logger.error("é”™è¯¯ï¼šå‚æ•°æ•°é‡ä¸æ­£ç¡®ã€‚")
        logger.error("ä½¿ç”¨æ–¹æ³•ï¼špython T-Bot.py [<JSONæ–‡ä»¶è·¯å¾„> <ä¸‹è½½ç›®å½•>]")
        logger.error("ç¤ºä¾‹ï¼š")
        logger.error("ä½¿ç”¨å‚æ•°ï¼špython T-Bot.py ../output/2000-01/2000-01-01.json ../downloads(é»˜è®¤)")
        logger.error("ä½¿ç”¨é»˜è®¤ï¼špython T-Bot.py")
        sys.exit(1)


if __name__ == "__main__":
    try:
        main()
        logger.info("ğŸ æ‰€æœ‰å¤„ç†ä»»åŠ¡å·²å®Œæˆï¼")
    except KeyboardInterrupt:
        logger.warning("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ğŸ’¥ æœªå¤„ç†çš„å¼‚å¸¸: {str(e)}")
        sys.exit(1)
